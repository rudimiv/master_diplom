\section{Введение} \label{section:introduction}


\subsection{Машинное обучение}
\textit{Машинное обучение (Machine Learning)} – обширный подраздел теории искусственного интеллекта, математическая дисциплина, использующая разделы математической статистики, численных методов оптимизации, теории вероятностей, математического анализа и линейной алгебры. 
% Machine learning algorithms build a mathematical model of sample data, known as "training data", in order to make predictions or decisions without being explicitly programmed to perform the task.
Алгоритмы машинного обучения формируют математическую модель данных из множества доступных примеров (обучение на основе обучающей выборки), которая позволяет затем алгоритму делать предсказания или принимать решения. 
% Данный подход позволяет изебжать явного программирования данной задачи.

% В настоящее время ...

Один из подразделов машинного обучения является \textit{обучение по признакам (Feature Learning, Represenation Learning)}. Данный набор техник, позволяют системе автоматически обнаружить представления, необходимые для выявления признаков или классификации исходных (сырых) данных. Это заменяет ручное конструирование признаков и позволяет машине как изучать признаки, так и использовать их для решения специфичных задач, что в свою очередь приводит к лучшим результатам и позволяет системам ИИ быстро адаптироваться к новым задачам с минимальным вмешательством человека. В то время как процесс ручного конструирования признаков может затягиваться на года и требует приложения огромного количества усилий со стороны исследователей, процесс автоматического извлечения признаков обычно занимает от нескольких часов до нескольких дней с приложением минимальных усилий со стороны человека \cite{DLB}.

Одной из основных проблем обучения по признакам является сложность отделения факторов изменчивости данных (к примеру, изменение освещения или наклона) от самих данных, так-как подобные факторы обычно влияют на все части данных, которые доступны. Чтобы справиться с такой задачей необходимо выделять высокоуровневые или абстрактные признаки, извлечение которых может быть крайне сложно \cite{DLB}. Одним из решений данной проблемы является глубинное обучение.

\textit{Глубинное обучение (Глубокое обучение, Deep Learning)} является подразделом обучения по признакам и характеризуется как класс алгоритмов машинного обучения, \cite{deng-yu} который:

\begin{itemize}

\item Использует каскад нелинейных фильтров для извлечения признаков и преобразований. Каждый последующий слой получает на вход выходные данные предыдущего слоя.

\item Формирует в процессе обучения слои на нескольких уровнях представлений, которые соответствуют различным уровням абстракции; слои образуют иерархию понятий.

\end{itemize}
%можно вставить картинку из MIT
% Deng, L.; Yu, D. (2014). “Deep Learning: Methods and Applications” (PDF). Foundations and Trends in Signal Processing. 7 (3—4): 1—199. DOI:10.1561/2000000039.


Таким образом глубинное обучение решает одну из основных проблем обучения по признакам, позволяя извлекать высокоуровненвые представления. Тем не менее для успешной работы алгоритмов глубинного обучения необходимы большие вычислительные мощности и большие объемы обучающей выборки. К сожалению, получение подобного объема данных обычно сопряжено с большими трудностями и требует большого числа человеческих, временных и денежных ресурсов. Одним из потенциальных решений данной проблемы является генерация синтетических (искусственных) данных. 


% Synthetic data is "any production data applicable to a given situation that are not obtained by direct measurement
%Synthetic data is information that's artificially manufactured rather than generated by real-world events. Synthetic data is created algorithmically, and it is used as a stand-in for test datasets of production or operational data, to validate mathematical models and, increasingly, to train machine learning models

\subsection{Синтетические данные}

\textit{Синтетические (искусственные) данные} - данные, полученные искусственно (синтезированные), то есть, не прибегая к непосредственному измерению в реальности. При этом подразумевается, что синтетические данные эмулируют реальные данные с сохранением статистических зависимостей, то есть переносят свойства реальных данных на синтезируемые. Конечная цель подобной эмуляции -- создание алгоритма, позволяющего генерировать данных на основе реальных. Синтетические данные при их анализе должны приводить к тем же результатам и выводам, что и реальные.

% Synthetic data is increasingly being used for machine learning applications: a model is trained on a synthetically generated dataset with the intention of transfer learning to real data. Efforts have been made to construct general-purpose synthetic data generators to enable data science experiments.[13] In general, synthetic data has several natural advantages:

В общем случае, синтетические данные имеют следующие преимущества:
\begin{itemize}
\item Если имеется алгоритм для генерации данных, то можно практически без затрат получить необходимое количество данных
\item Синтетические данные могут быть безошибочно размечены, в то время как, это может быть крайне затратно или невозможно сделать на реальных данных
% \item the synthetic environment can be modified to improve the model and training;
\item Синтетические данные могут быть использованы в качестве замены для определенных частей реальных данных (к примеру, если реальные данные содержат конфидециальную информацию)

\end{itemize}

Использование синтетических данных для пополнения обучающей выборке находит применение во многих областях, особенно в задачах компьютерного зрения и в задачах обнаружения объектов. К примеру в работе \cite{peng-3d} трехмерное синтетическое окружение на основе CAD моделей позволило дополнить обучающую выборку двухмерных изображений, что привело к увеличению эффективности работы алгоритма распознования. 




%Advances in generative models, in particular generative adversarial networks (GAN), lead to the natural idea that one can produce data and then use it for training. This fully synthetic approach has not yet materialized,[15] although GANs and adversarial training in general are already successfully used to improve synthetic data generation.[16].


\subsection{Генеративные модели}


% https://mighty.ai/blog/at-a-glance-generative-models-synthetic-data/
Одним из методов для генерации синтетических данных являются \textit{генеративные модели}.

Сами генеративные модели как концепция существуют уже не первое десятилетие и различными исследователями было создано большое количество различных моделей \cite{sanchez-at-glance}, \cite{lrgm-cloud}, :

\begin{itemize}

\item \textit{Генеративно-состязательные сети (Generative Adversarial Networks, GANs)}: обучение модели похоже на игру, в которой соревнуются \textit{генеративная (генератор)} и \textit{дискриминативная (дискримантор)} сети, которые и составляют два основных элемента данной модели \cite{gan-1}, \cite{gan-super}.

\item \textit{Вариационные автоэнкодер (Variational Autoencoders, VAEs)} использует архитектуру кодировщик-декодировщик, при этом использует вероятностный подход для семплирований переменных в латентном пространстве.

% Variational Autoencoders (VAEs): using probabilistic graphical models and variational Bayesian methods to derive a “lower bound”

\item \textit{Авторегрессионные модели (Autoregressive models)}: обучают модель определять значения пикселя на основе значений пикселей слева и снизу.

\item \textit{Модели основанные на смеси гауссовых распределений (Gaussian mixture model, GMM)}. GMM - вероятностная модель для аппроксимации распределения данных в виде суммы гауссовых распределений \cite{bishop}.

\item \textit{Модели основанные на статистическом анализе формы объекта (3D statistical shape spaces)}. Данная модель описывает данные в виде суммы <<средней>> формы по всем данным и вектора флуктуаций. Получив среднюю форму и зная диапазоны варьирования вектора флуктуаций, можно получать новые объекты, сохраняя статистические свойства исходных объектов \cite{stat-shape-1}, \cite{stat-shape-2}.

%Autoregressive models: training the network to produce individual pixels based on those above and to the left of them
\end{itemize}

% https://en.wikipedia.org/wiki/Synthetic_data
Последние успехи в области построения генеративных моделей, особенно в генеративно-состязательных сетях, естественным образом приводят к мысли о том, что подобные модели способны самостоятельно синтезировать все необходимые данные для последующего обучения. Подобный подход, полностью основанный на синтетических данных, пока не реализован, хотя состязательные методы и генеративно-состязательные сети в частности уже существенно улучшили генерацию синтетических данных. К примеру, в работе \cite{Shrivastava-gap-real} предлагаются различные методы по генерации высококачественных и близких к реальным изображений.

\subsection{Машинное обучение для обработки трехмерных объектов}

Одной из возможных областей применения различных нейронных сетей является обработка тремерных изображений. В последнее время это область особенно активно развивается в связи с полученим больших объемов трехмерных данных с лидаров, которые активно используются в автономных траснпортных средствах, с трехмерных сканеров, которые все чаще используются в различных областях человеческой деятельности (к примеру, в медицине), CAD моделей, сцен из компьютерных игр и симуляторов.


Растет и количество предложенных моделей и методов для задач распознавания и сегментации трехмерных объектов \cite{point-net-plus}, \cite{seg-cloud}, \cite{octree-based}, \cite{spherical-conv-1}, \cite{spherical-cnn}.


Одной из основных проблем, с которыми сталкиваются, при работе с трехмерными объектами, представленными \textit{полигональными сетки (polygon meshes)} является их чрезмерная разреженность и неравномерность \cite{pu-net}. Альтернативой этому выступает использование регулярных сеток - \textit{вокселей (voxels, трехмерных пикселей, occupancy grid)}, которые позволяют переносить методы, аппробированные на двумерных данных в эту область. Но при таком подходе, в случае низкого уровня дискретизации, теряется информация, а в случае повышение уровня дискртизации -- приводит к огромному потреблению памяти. 


\subsection{Проблематика}

В задачах обработки трехмерных объектов методами глубинного обучения, как и во всех задачах глубинного обучения, очень часто возникает проблема недостатка данных для обучения. Причины возникновения такой проблемы могут быть разными: от невозможности получить и разметить эти данные из-за недостатка ресурсов, до ограничений из-за конфидециальности данных.

Все эти факторы естественным образом приводят к идее использовать различные генеративные модели для генерации синтетических данных. В последние несколько лет исследователями были предложены различные попрождающие модели как на основе генеративно-состязательных моделей \cite{3d-gan}, так и на основе вариационных энкодировщиков \cite{3d-autoencoder}. Стоит отметить, что входные данные для данных моделей были представлены в виде  вокселей. В новых работах уже предложены методы, которые позволяют работать с облаками точек \cite{adversarial-autoencoder}, \cite{lrgm-cloud}. 

Целью данной работы является построение новых алгоритмов генерации синтетических 3D данных на основе методов машинного обучения. Обобщая вышесказанное, можно с уверенностью сказать, что задача генерации трехмерных синтетических данных нова и актуальна. 